{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PCA to see which feature has how much influence\n",
    "* implement scoring function, eating food gives plus, getting smaller distance to food gives plus, reducing distance to enemy wolf gives minus etc.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree, naive_bayes, svm\n",
    "import ast\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all the constants from the game available here to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[General_Constants]\n",
    "FIELD_WIDTH = 19\n",
    "FIELD_HEIGHT = 15\n",
    "\n",
    "#[Game_Constants]\n",
    "NO_ITERATIONS = 100\n",
    "MAX_CALC_TIME = 100000\n",
    "\n",
    "#[Field_Constants]\n",
    "CELL_EMPTY = '.'\n",
    "CELL_SHEEP_1 = 'S'\n",
    "CELL_SHEEP_1_d = 'U'\n",
    "CELL_WOLF_1 = 'W'\n",
    "CELL_SHEEP_2 = 's'\n",
    "CELL_SHEEP_2_d = 'u'\n",
    "CELL_WOLF_2 = 'w'\n",
    "CELL_GRASS = 'g'\n",
    "CELL_RHUBARB = 'r'\n",
    "CELL_FENCE = '#'\n",
    "\n",
    "\n",
    "#[Movements]\n",
    "MOVE_NONE = 0\n",
    "MOVE_UP = -1\n",
    "MOVE_DOWN = 1\n",
    "MOVE_LEFT = -2\n",
    "MOVE_RIGHT = 2\n",
    "\n",
    "#[Awards]\n",
    "AWARD_RHUBARB = 5\n",
    "AWARD_GRASS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all games into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../training_data/subset1\" \n",
    "all_files = glob.glob(path + \"/*.csv\")   \n",
    "\n",
    "training_data = []\n",
    "\n",
    "#load the data into a pandas frames\n",
    "for file in all_files:\n",
    "    game_data = pd.read_csv(file,index_col=False)\n",
    "    reason = game_data.iloc[-1][6]\n",
    "    \n",
    "    #if the reason is found, add it to each line to fill out the blanks\n",
    "    if type(reason) is str:\n",
    "        for index,row in game_data.iterrows():\n",
    "            game_data.loc[index,'reason'] = reason\n",
    "\n",
    "    #else there was no reason, implying the game reached the number of iterations\n",
    "    else:\n",
    "        for index,row in game_data.iterrows():\n",
    "            game_data.loc[index,'reason'] = 'max_iterations'    \n",
    "    \n",
    "    training_data.append(game_data)\n",
    "\n",
    "#preview the final 5 lines\n",
    "training_data[-1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection and Instance selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Note: \n",
    "I imported the class of my Python file to use the same functions and prevent duplicating code. I have to use the same feature preparation in the training phase as in the prediction pmhase. Thus all feature engineering is done in the python file (this also allows for easier debugging)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sheep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection:\n",
    "My baseline was the Search Algorithm from assignment 1. I used the movement determined by the search algorithm as a feature for my sheep. I then tried multiple features and looked at their correlation to the actual move made. I dropped features with poor correlation. Thus, I ended up with taking the player into consideration, as player 1 always starts in the top, player 2 on the bottom. Also, the direction of the enemy sheep has an influence, probably favoring an agressive playstile.\n",
    "\n",
    "### Data Selection\n",
    "I used all rows from the winning side performing a sheep-move. I used different configurations of agents from assignment 1 and ran them on random maps to scrape the results. I didn't use the provided data, as I didn't know the quality of the games, as the second worst agents still wins against the worst agent resulting it to be a \"win\" although both agents are in fact not optimal. I also ignored all games that ended because of an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload  # to get changes in code\n",
    "import chriweb_a2\n",
    "chriweb_a2 = reload(chriweb_a2)\n",
    "ii = chriweb_a2.IntrepidIbex()\n",
    "\n",
    "X_sheep = []\n",
    "Y_sheep = []\n",
    "number_moves = 0\n",
    "\n",
    "for game in training_data:\n",
    "    \n",
    "    #we want to learn from the winning player, which is the player with the highest score:\n",
    "    if game.iloc[-1][4] < game.iloc[-1][5]:\n",
    "        sheep_label = 's'\n",
    "        wolf_label = 'W'\n",
    "        figure = 1\n",
    "    \n",
    "    elif game.iloc[-1][4] > game.iloc[-1][5]:\n",
    "        sheep_label = 'S'\n",
    "        wolf_label = 'w'\n",
    "        figure = 2\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    #for each game state in our training data\n",
    "    for index,row in game.iterrows():\n",
    "\n",
    "        #we don't want games that ended because of an error or because the sheep commited suicide\n",
    "        if row['reason'] not in ('sheep1 eaten','sheep2 eaten','max_iterations'):\n",
    "            continue\n",
    "\n",
    "        #we want to only learn from sheep\n",
    "        if row['turn_made_by'] not in ('player1 sheep','player2 sheep'):\n",
    "            continue\n",
    "            \n",
    "        #we want to only learn from winning player\n",
    "        if str(figure) not in row['turn_made_by']:\n",
    "            continue\n",
    "        \n",
    "        number_moves += 1\n",
    "        \n",
    "        #this is the move that we are learning from this game state\n",
    "        move = row['move_made']\n",
    "\n",
    "        #create empty feature array for this game state\n",
    "        game_features = []\n",
    "\n",
    "        #turn the field from before the move from a string back to a list\n",
    "        field = ast.literal_eval(row['field_before'])     \n",
    "                \n",
    "        game_features = ii.get_features_sheep(figure, field)  \n",
    "        \n",
    "        #add features and move to X_sheep and Y_sheep\n",
    "        X_sheep.append(game_features)\n",
    "        Y_sheep.append(move)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_investigate_s = pd.DataFrame(X_sheep)\n",
    "df_investigate_s['y'] = Y_sheep\n",
    "df_investigate_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See correlation of each feature to result. I dropped features that had not enough correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_investigate_s.corr()['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wolf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain here in text which feature you used for the wolf, and which data you used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection:\n",
    "My baseline was the Search Algorithm from assignment 1. I used the movement determined by the search algorithm as a feature for my wolf. I then tried multiple features and looked at their correlation to the actual move made. I dropped features with poor correlation. Thus, I ended up with the following features:\n",
    "* Player 1 or 2, as player 1 always starts in the top, player 2 on the bottom. \n",
    "* Direction needed to get to the enemy sheep (as the wolf needs to eat it)\n",
    "* Get the degrees of freedom of neighboring fields (reasoning could be to cut of enemy sheep?)\n",
    "\n",
    "### Data Selection\n",
    "I used all rows from the winning side performing a wolf-move. I used different configurations of agents from assignment 1 and ran them on random maps to scrape the results. I didn't use the provided data, as I didn't know the quality of the games, as the second worst agents still wins against the worst agent resulting it to be a \"win\" although both agents are in fact not optimal. I also ignored all games that ended because of an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload  # to get changes in code\n",
    "import chriweb_a2\n",
    "chriweb_a2 = reload(chriweb_a2)\n",
    "ii = chriweb_a2.IntrepidIbex()\n",
    "\n",
    "X_wolf = []\n",
    "Y_wolf = []\n",
    "number_moves = 0\n",
    "\n",
    "for game in training_data:\n",
    "    \n",
    "    #we want to learn from the winning player, which is the player with the highest score:\n",
    "    if game.iloc[-1][4] < game.iloc[-1][5]:\n",
    "        sheep_label = 's'\n",
    "        wolf_label = 'W'\n",
    "        figure = 1\n",
    "    \n",
    "    elif game.iloc[-1][4] > game.iloc[-1][5]:\n",
    "        sheep_label = 'S'\n",
    "        wolf_label = 'w'\n",
    "        figure = 2\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    rhubarb = 'r'\n",
    "    grass = 'g'\n",
    "\n",
    "    #for each game state in our training data\n",
    "    for index,row in game.iterrows():\n",
    "\n",
    "        #we don't want games that ended because of an error or because the sheep commited suicide\n",
    "        if row['reason'] not in ('sheep1 eaten','sheep2 eaten','max_iterations'):\n",
    "            continue\n",
    "\n",
    "        #we want to only learn from sheep\n",
    "        if row['turn_made_by'] not in ('player1 wolf','player2 wolf'):\n",
    "            continue\n",
    "            \n",
    "        #we want to only learn from winning player\n",
    "        if str(figure) not in row['turn_made_by']:\n",
    "            continue\n",
    "        \n",
    "        number_moves += 1\n",
    "        \n",
    "        #this is the move that we are learning from this game state\n",
    "        move = row['move_made']\n",
    "\n",
    "        #create empty feature array for this game state\n",
    "        game_features = []\n",
    "\n",
    "        #turn the field from before the move from a string back to a list\n",
    "        field = ast.literal_eval(row['field_before'])     \n",
    "        \n",
    "        game_features = ii.get_features_wolf(figure, field)  \n",
    "        \n",
    "        #add features and move to X_sheep and Y_sheep\n",
    "        X_wolf.append(game_features)\n",
    "        Y_wolf.append(move)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_investigate_w = pd.DataFrame(X_wolf)\n",
    "df_investigate_w['y'] = Y_wolf\n",
    "df_investigate_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_investigate_w.corr()['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Sheep Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test data to measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "x_train_s, x_test_s, y_train_s, y_test_s = model_selection.train_test_split(X_sheep, Y_sheep, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test sheep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allowed algorithms:\n",
    "* Naive Bayes (GaussianNB, MultinominalNB, ComplementNB, BernoulliNB)\n",
    "* Decision Tree\n",
    "* Support Vector Machine (SVC, NuSVC, LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheep_NB = naive_bayes.GaussianNB()\n",
    "# # sheep_NB = naive_bayes.MultinomialNB()\n",
    "# # sheep_NB = naive_bayes.ComplementNB()\n",
    "# # sheep_NB = naive_bayes.BernoulliNB()\n",
    "# sheep_NB = sheep_NB.fit(x_train_s,y_train_s)\n",
    "# y_pred_s = sheep_NB.predict(x_test_s)\n",
    "\n",
    "# cm = confusion_matrix(y_test_s, y_pred_s.tolist())\n",
    "# recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "# precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "\n",
    "# print(cm)\n",
    "# print(np.mean(recall))\n",
    "# print(np.mean(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheep_tree = tree.DecisionTreeClassifier()\n",
    "# sheep_tree = sheep_tree.fit(x_train_s,y_train_s)\n",
    "# # sheep_tree = sheep_tree.fit(np.array(x_train_s).reshape(-1,1),y_train_s)\n",
    "# # y_pred_s = sheep_tree.predict(np.array(x_test_s).reshape(-1,1))\n",
    "# y_pred_s = sheep_tree.predict(x_test_s)\n",
    "\n",
    "# cm = confusion_matrix(y_test_s, y_pred_s.tolist())\n",
    "# recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "# precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "\n",
    "# print(cm)\n",
    "# print(np.mean(recall))\n",
    "# print(np.mean(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision/recall is similar to the decision tree, but I choose SVM as it performed better when run against my agent from assignment 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheep_svm = svm.SVC()\n",
    "sheep_svm = sheep_svm.fit(x_train_s,y_train_s)\n",
    "y_pred_s = sheep_svm.predict(x_test_s)\n",
    "\n",
    "cm = confusion_matrix(y_test_s, y_pred_s.tolist())\n",
    "recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "\n",
    "print(cm)\n",
    "print(np.mean(recall))\n",
    "print(np.mean(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train wolf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "x_train_w, x_test_w, y_train_w, y_test_w = model_selection.train_test_split(X_wolf, Y_wolf, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wolf_tree = tree.DecisionTreeClassifier()\n",
    "wolf_tree = wolf_tree.fit(x_train_w,y_train_w)\n",
    "y_pred_w = wolf_tree.predict(x_test_w)\n",
    "\n",
    "cm = confusion_matrix(y_test_w, y_pred_w.tolist())\n",
    "recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "\n",
    "print(cm)\n",
    "print(np.mean(recall))\n",
    "print(np.mean(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Save your models to files here using pickle. Change the [uzhshortname] to your own UZH shortname. This name needs to match the model that you caller in your python player file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheep_filename = 'chriweb_sheep_model.sav'\n",
    "wolf_filename = 'chriweb_wolf_model.sav'\n",
    "\n",
    "pickle.dump(sheep_svm,open(sheep_filename,'wb'))\n",
    "pickle.dump(wolf_tree,open(wolf_filename,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
